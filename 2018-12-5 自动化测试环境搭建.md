# 自动化工具选型



## 自动化需求

FISCO-BCOS项目对外提供三种接口，分别是控制台、RPC、和SDK，其中控制台和SDK需要用户频繁的通过ssh协议往主机发送命令的方式来完成操作和校验测试结果，因此，需要自动化平台提供如下功能来完成让每个测试人员进行自动化用例设计的能力 

## 自动化方案比较

根据项目自动化详细需求，比较了公司自动化平台和RF工具对应能力

1. 自动化平台应该能够提供控制和管理多个SSH会话的能力，需要保持长连接，能够让用户在该会话上完成多个发送命令的操作，同时，最好可以通过索引或者别名能切换到另外一个会话上进行相应操作

   ----公司的自动化平台脚本的返回值都是str形式，只能用来进行参数传递和数据校验，无法保持住SSH会话

   ----RF工具基于python开发，每个关键字可以返回任何python对象，引入第三方库SSHLIBRARY，我们只需要对其依据业务需求进行二次开发，即可满足保持SSH会话，发送多条命令的操作

   ------公司的自动化平台，对第三方用户只提供很少的api可以使用，具体到本项目，可以使用的是runscript和chechkerr操作，且不会为第三方应用提供需求开发，导致我们的用例的实际逻辑全部要通过shell脚本来实现，使写作的用例不具备可读性，同时全局变量也不方便使用，使用例缺乏可移植性

   -----RF工具是开源的，代码全部对用户开放，我们可以依据业务需求开发我们想要的任何功能；同时提供ui，用例方便阅读，支持测试套件定义全局变量，可以实现修改环境变量，就可以让用例在不同设备上运行的能力

2. 自动化平台需要提供详细的日志功能，日志应该能够详细记录用户发送的每一条命令，同时能够把命令的回显信息打印出来，方便用户进行出错定位

   ------公司自动化平台日志功能基本是靠print功能来是实现，调试能力差，定位能力差

   ------RF日志采用logging模块，具备调试功能，定位问题快速

3. 自动化平台需要提供断言功能，当一个脚本出现用户不期望的预期结果时，能够让用户做出判断，该步骤是成功还试失败，同时需要支持失败时是否能够跳过接下来的步骤直接运行下个用例，还是继续运行下面的用例

   ------主要通过checkerr来判断用例是否失败

   ------有assert来进行用例判断，功能强大

4.    自动化平台应该依据测试套件来设置环境变量，因为有频繁的登录操作，我们希望通过修改变量值，就可以移植用例到另外一个环境上继续执行

5. 自动化平台，应该提供用户自定义高级脚本的功能；由于我们需要经常往命令行输入命令，该功能，可以支持我们把N条命令定义成一个关键字的能力，同时通过关键字的参数，就可以实现多条命令的参数化

   --------公司自动化平台正在开发关键字复用功能，暂时不支持

   -------RF提供丰富的高级关键字定义，让不具备语言能力的写作者，也能复用关键字，提高了用例可读性和效率

RF工具作为开源工具，并在自动化圈广泛使用，其运行稳定，性能好

提供丰富的日志、报告功能，并能和jekins进行集成，可以快速进行CI

丰富的文档和大量的博客，方便学习和使用

> 综合上述情况，建议采用RF工具进行自动化

采用RF存在的主要问题：

公司自动化平台主要定位是任务调度和用例管理，使用RF工具，需要和公司自动化平台对接任务；

使用RF工具写作自动化用例，无法对测试用例和需求进行关联，后期需要度量自动化用例对用例和需求的覆盖率可能存在开发任务（暂时公司自动化平台也不具备度量能力）；

公司自动化可以跳过堡垒机，但是RF无法跳过堡垒机，需要在云环境中增加一台win server服务器，在上面搭建测试环境，每个测试人员，通过远程桌面进行用例写作和执行

公司自动化平台采用数据库存储数据，RF采用git存储数据

## 自动化目标

#### 自动化价值

自动化的价值不是用来发现多少bug，而是将重复的工作固化（包括用例设计固化、执行步骤固化），节省资源和提高工作效率，将测试人员的精力用于需求学习，方案学习，以设计更高质量的用例，而不是疲于执行用例。

1.自动化一般用来进行版本转入时的冒烟测试，和发版前的回归测试，冒烟测试用例选择业务主要的应用场景和高优先级的测试用例，控制4小时出一次测试结果（一天可以验证多个版本）；

2.回归测试会执行所有的自动化用例，尽量提高自动化用例对手工用例的覆盖，减少手工用例的执行时间，回归测试用例时间控制12个小时（理论上一天验证一个版本）。

3.自动化可以提高版本质量，由于大部分用例通过自动化完成，避免了人员的重复劳动

#### 自动化目标

1.需要确定自动化用例对手工用例的覆盖率

2.需要确定一个自动化用例运行时间目标

3.需要做到人人可以自动化

# RF工具安装

**1.    **安装****python 2.7.9****（自带****pip****）******

下载python，双击msi文件安装（已经下载）

https://www.python.org/ftp/python/2.7.9/python-2.7.9.amd64.msi注意：安装路径不要有空格，可能会引起pip的使用问题

**2.     ****配置环境变量****Path******

我的电脑 – 右键 – 高级系统设置– 环境变量 – 编辑path

添加 D:\Python27\;D:\Python27\Scripts\; >如果已安装过strawberry，需将python的变量置于strawberry之前，如：D:\Python27\;D:\Python27\Scripts\;C:\strawberry\c\bin;

检查是否安装成功：

 

**3.    ****安装****robotframework**

Cmd下pip install robotframework

出现如下提示则表示安装成功：

uccessfullyinstalled robotframework Cleaning up... `

** **

4.    安装wxPython：

http://sourceforge.net/projects/wxpython/files/wxPython/2.8.12.1/wxPython2.8-win64-unicode-2.8.12.1-py27.exe/download

下载完后，手动执行exe安装。

5.    安装RIDE

cmd执行pip install robotframework-ride

cmd执行python C:\Python27\Scripts\ride.py即可启动

6.    安装ssh库

      在安装SSHLibrary以前，我们需要安装它的支撑库Paramiko ，pip install paramiko

      pip install robotframework-SSHLibrary



# RF工具使用

#### 新建测试套件和测试用例

在你安装好RF-ride之后，桌面就会生成一个RIDE图标。双击启动，界面如下：

 ![img](https://images0.cnblogs.com/i/311516/201407/271759082445273.png) 

 下面我们就一步一步的创建第一条用例，至于细节不多解释，只是对RF框架写用例有个感性的认识。

 

 

**创建测试项目                                          **

 选择菜单栏file----->new Project

![img](https://images0.cnblogs.com/i/311516/201407/271800040724917.png)

Name 输入项目名称。

Type 选择Directory。

 

 

**创建测试套件                                            **

  右键点击“测试项目”选择new Suite 选项

![img](https://images0.cnblogs.com/i/311516/201407/271800455102557.png)

Name 输入项目名称。

Type 选择File。

 

 

**创建测试用例                                                  **

​     右键点击“测试项目”选择new Test Case 

![img](https://images0.cnblogs.com/i/311516/201407/271801302607351.png)

用例只需要输入用例name ，点击OK即可。

#### 导入库文件和新增资源

1.新建一个资源文件，命名为importall，导入需要的库和针对整个测试套件的全局变量

2.新建一个资源文件，将测试套件下需要的环境资源定义成全局变量，后续写用例里时，只能输入参数值，不能够直接传值，影响用例的移值性

3.新增一个resource（资源）文件，可以对library提供的关键字进行复用，提供更高级的关键字，让写作用例的人具有封装高级关键字的能力

工具本身提供了大量的内部关键字，可以对用例的执行结果进行判断，从而决定用例是成功还是失败，按F5可以调出帮助文档，同时官网上提供了详细的说明，可以参考文档进行用例写作

#### Help 文档（Built-In）

http://robotframework.org/robotframework/#user-guide

#### 自定义库介绍

##### RPCREQUEST

HTTP Request库，用来构造http的json报文。



```
to_ordered_dict：用来构建ordered dict对象，该对象传送给requests的post的对象
```

```
send_request：发送http报文，用来查询快高信息等
```

```
get_response_result：解析http的response.content，将其转换成dict object，依据传入的key获取值
```

封装关键字getblocknumber块高关键字

该关键字封装完成后，用户只需要输入需要查询的节点的IP和对应的跑rpcPort端口，就可以查询到快高；同时可以通过修改methond和params的值，可以封装成其他查询关键字。

getblocknumber

    [Arguments]    ${listenIP}    ${rpcPort}    # IP:PORT
    ${jsonrpc}    jsonrpc    2.0
    ${method}    method    eth_blockNumber
    ${params}    params    ${EMPTY}
    ${random}    Evaluate    random.randint(0, 100000)    modules=random
    ${id}    id    ${random}
    ${dict}    to_ordered_dict    ${jsonrpc}    ${method}    ${params}    ${id}
    ${responseContent}    send_request    post    ${listenIP}:${rpcPort}    ${dict}
    ${block}    get_response_result    ${responseContent}    result
    [Return]    ${block}
##### BCOSLIBRARY

继承了SSHLIBRARY，通过该Library 用户可以登录到远程linux机器上，执行对应的cmd。为了方便用例写作，封装了部分功能，让用户可以快速完成自动化用例的写作。

接下来将简单介绍一下每个关键字的作用，以及如何调用。



#### Tag的使用

首先，为什么要打tag

1、tag的标示可以展示在测试报告、日志中，便于查看用例。

2、可以根据tag统计用例。

3、有了tag，可以执行包含这些tag的用例，或者执行不包含这些tag的用例。

4、根据tag，可以区分出哪些用例是关键用例。

其次，如何打tag打tag的方式有三种

1、在文件夹下打tag，这样文件夹下的所有用例都已经自动打上该tag。

文件夹下打tag

2、在suit下打tag，这样suit下的测试用例都加上了tag号




suit下打tag
suit下打tag分为两种：一种是Force Tags,一种是Default Tags。Force Tags：suit下面所有的测试用例都被打上这个tagDefault Tags：suit下面的测试用例如果没有打tag，就会用这个默认tag，如果打了tag，就用自己打的tag。3、在测试用例上打tag。




测试用例打tag
最后，怎么打tag看起来会更便捷可以在各个文件夹下打文件夹名字的tag，这样就可以根据tag单独的跑该文件夹下的用例，查看测试报告也更好看些。在一些重要的用例上打上tag，可以单独跑关键用例。某些用例如果不想执行，可以打上tag，设置不执行。

作者：小叮当爱学习
链接：https://www.jianshu.com/p/f819bf56ad52
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。

# Postman工具使用方法

#### Postman插件的安装

1.    登录<https://chrome.google.com/webstore/category/extensions>，然后在搜索框中输入postman，选择下图中的Tabbed Postman，然后单击“Add to chome”

2.    定义全局变量

      ![postman-添加全局变量](D:\work\picture\postman-添加全局变量.png)

3.    新增容器

      ![postman-添加Collections](D:\work\picture\postman-添加Collections.png)

4.    新增request

      ![postman-发送请求](D:\work\picture\postman-发送请求.png)

5.    导入和导出容器

      ![postman-导入导出](D:\work\picture\postman-导入导出.png)





## 测试环境



以下是当前测试组大家在用的机器，主要关注的是P2Pport（外网）外网端口，这部分端口代表在使用外网IP节点连接时能通，范围是8301-8320，以及30801-30820。为防大家在搭建跨服务器交叉使用端口冲突，对使用范围做了一下规划

port（内网）端口在内网时使用没有限制，也是考虑跨服务器使用冲突，大家也尽量在规定的范围内使用

  

| owner | P2Pport（外网） | port（内网）    | 外网             | 内网             |
| ----- | ----------- | ----------- | -------------- | -------------- |
| 夏石龙   | 8306-8310   | 8526-8550   | 119.29.94.36   | 10.107.105.134 |
| 张志刚   | 8301-8305   | 8501-8525   | 119.29.246.185 | 10.107.105.107 |
| 李磊    | 8311-8315   | 8551-8575   | 118.89.33.89   | 10.107.105.106 |
| 冀猛猛   | 8316-8320   | 8576-8600   | 139.199.16.52  | 10.107.105.112 |
| 邓小聪   | 30801-30805 | 30901-30925 | 123.207.79.200 | 10.107.105.92  |
| 孙文秋   | 30806-30810 | 30926-30950 | 119.29.219.217 | 10.107.105.59  |
| 曾水彦   | 30811-30815 | 30951-30975 | 119.29.64.127  | 10.107.105.143 |
| 自动化   |             |             | 123.207.38.144 | 10.107.105.34  |

#   Netdata 学习----linux实时性能监控工具

通常来说，作为一个Linux的SA，很有必要掌握一个专门的系统监控工具，以便能随时了解系统资源的占用情况。下面就介绍下一款Linux性能实时监测工具-Netdata，它是Linux系统实时性能监测工具，以web的可视化方式展示系统及应用程序的实时运行状态（包括cpu、内存、硬盘输入/输出、网络等linux性能的数据）。Netdata的web前端响应很快，而且不需要Flash插件。 UI很整洁，保持着 Netdata 应有的特性。第一眼看上去，你能够看到很多图表，幸运的是绝大多数常用的图表数据（像 CPU，RAM，网络和硬盘）都在顶部。如果你想深入了解图形化数据，你只需要下滑滚动条，或者点击在右边菜单的项目。通过每个图表的右下方的按钮，Netdata还能控制图表的显示，重置，缩放。Netdata文档地址：<https://github.com/firehol/netdata/wiki>

Netdata用可视化的手段，将被监测者最细微的细节，展现了出来。这样便可以清晰地了解linux系统和应用程序此时的状况。

#### Netdata主要功能:

`优美的界面：bootstrap框架下的控制界面, 酷炫（主要是dark主题，light主题就没这感觉了）`

`自定义的控制界面：你可以使用简单的HTML代码去自定义控制界面(不需要使用javascript)`

`极其的快速而高效：程序使用C进行编写(默认安装下，预计只有2%的单核CPU使用率和少许的内存使用率)`

`零配置：你只需要去安装它，接着它就会自动地监测一切数据`

`零依赖：它的静态网络文件和网络接口拥有自己的网络服务器. netdata有自己的web server， 提供静态web文件和web API`

`可扩展：用它自身的插件API(可以使用许多方式来制作它的插件，从``bash``到node.js),你可以检测任何可以衡量的数据。`

`可嵌入：它可以在任何Linux内核可以运行的地方运行`

`零维护：只管跑上！`

`匪夷所思的快。。。所有请求每个metreic都在0.5ms内响应，即便是一台烂机器`

`非常高效，每秒采集数千个指标，但仅占cpu单核1%，少量MB的内存以及完全没有磁盘IO`

`提供复杂的、各种类型的告警，支持动态阈值、告警模板、多种通知方式等`

`支撑多种时间序列后端服务，比如graphite, opentsdb, prometheus, json document DBs`

#### **监测内容**

下面是Netdata目前检测的内容（大多数都不需要进行配置，安装后即可开始监测）

`1.CPU的使用率,中断，软中断和频率(总量和每个单核)`

`2.RAM，互换和内核内存的使用率（包括KSM和内核内存deduper）`

`3.硬盘输入/输出(每个硬盘的带宽，操作，整理，利用等)`

`4.IPv4网络（数据包，错误，分片）：`

`TCP：连接，数据包，错误，握手`

`UDP:数据包，错误`

`广播：带宽，数据包`

`组播：带宽，数据包`

`5.Netfilter``/iptables` `Linux防火墙(连接，连接跟踪事件，错误等)`

`6.进程(运行，受阻，分叉，活动等)`

`7.NFS文件服务器，v2,v3,v4(输入/输出，缓存，预读，RPC调用)`

`8.网络服务质量（唯一一个可实时可视化网络状况的工具）`

`9.应用程序，通过对进程树进行分组（CPU,内存，硬盘读取，硬盘写入，交换，线程，管道，套接字等）`

`10.Apache Web服务器状态(v2.2, v2.4)`

`11.Nginx Web服务器状态`

`12.Mysql数据库（多台服务器，单个显示：带宽，查询``/s``, 处理者，锁，问题，临时操作，连接，二进制日志，线程，innodb引擎等）`

`13.ISC Bind域名服务器（多个服务器，单个显示：客户，请求，查询，更新，失败等）`

`14.Postfix邮件服务器的消息队列（条目，大小）`

`15.Squid代理服务器（客户带宽和请求，服务带宽和请求）`

`16.硬件传感器（温度，电压，风扇，电源，湿度等）`

`17.NUT UPSes（负载，充电，电池电压，温度，使用指标，输出指标）`

`可以监测任意数量的SNMP服务，不过你需要进行配置，还可以对此软件进行扩展，可以使用任何语言编写插件，以此来从任何来源收集数据`

#### Netdata的部署过程（Cetnos下）

yum install zlib-devel gcc make git autoconf autogen guile-devel automake pkgconfig

`# git clone https://github.com/firehol/netdata.git --depth=1`

`# cd netdata`

`# ./netdata-installer.sh`

 

`注意上面要使用root权限，执行命令后的提示信息也很丰富有趣`

 

`安装完后，还可以根据wiki所说的配置开机启动，照做之后执行service netdata start启动服务，可以访问http:``//localhost``:19999/ 看到监控界面。`

# 二次开发

## 内部插件增加

可以按照用户、用户组、进程组来定制app.plaign

sudo /etc/netdata/edit-config apps_groups.conf #

添加如下配置项

fisco: *fisco*

group: `ps -ef | grep fis | grep xsl |grep -v grep | cut -c 9-15`      该方法不行

sudo systemctl stop netdata    sudo systemctl start netdata

## 扩展插件-python



#### How to write a new module[¶](https://docs.netdata.cloud/collectors/python.d.plugin/#how-to-write-a-new-module)

Writing new python module is simple. You just need to remember to include 5 major things:
- **ORDER** global list
- **CHART** global dictionary
- **Service** class
- **_get_data** method
\- all code needs to be compatible with Python 2 (**≥ 2.7**) *and* 3 (**≥ 3.1**)

If you plan to submit the module in a PR, make sure and go through the [PR checklist for new modules](https://docs.netdata.cloud/collectors/python.d.plugin/#pull-request-checklist-for-python-plugins) beforehand to make sure you have updated all the files you need to.

For a quick start, you can look at the [example plugin](https://github.com/netdata/netdata/tree/master/collectors/python.d.plugin/example/example.chart.py).

#### Global variables `ORDER` and `CHART`[¶](https://docs.netdata.cloud/collectors/python.d.plugin/#global-variables-order-and-chart)

`ORDER` list should contain the order of chart ids. Example:

```
ORDER = ['first_chart', 'second_chart', 'third_chart']

```

`CHART` dictionary is a little bit trickier. It should contain the chart definition in following format:

```
CHART = {
    id: {
        'options': [name, title, units, family, context, charttype],
        'lines': [
            [unique_dimension_name, name, algorithm, multiplier, divisor]
        ]}

```

All names are better explained in the [External Plugins](https://docs.netdata.cloud/collectors/) section.
Parameters like `priority` and `update_every` are handled by `python.d.plugin`.

#### Pull Request Checklist for Python Plugins[¶](https://docs.netdata.cloud/collectors/python.d.plugin/#pull-request-checklist-for-python-plugins)

This is a generic checklist for submitting a new Python plugin for Netdata. It is by no means comprehensive.

At minimum, to be buildable and testable, the PR needs to include:

- The module itself, following proper naming conventions: `python.d/<module_dir>/<module_name>.chart.py`
- A README.md file for the plugin under `python.d/<module_dir>`.
- The configuration file for the module: `conf.d/python.d/<module_name>.conf`. Python config files are in YAML format, and should include comments describing what options are present. The instructions are also needed in the configuration section of the README.md
- A basic configuration for the plugin in the appropriate global config file: `conf.d/python.d.conf`, which is also in YAML format. Either add a line that reads `# <module_name>: yes` if the module is to be enabled by default, or one that reads `<module_name>: no` if it is to be disabled by default.
- A line for the plugin in `python.d/Makefile.am` under `dist_python_DATA`.
- A line for the plugin configuration file in `conf.d/Makefile.am`, under `dist_pythonconfig_DATA`
- Optionally, chart information in `web/dashboard_info.js`. This generally involves specifying a name and icon for the section, and may include descriptions for the section or individual charts.



## 扩展插件-charts.d.plugin

https://docs.netdata.cloud/collectors/charts.d.plugin/

charts.d.plugin` looks for scripts in `/usr/lib/netdata/charts.d`.
The scripts should have the filename suffix: `.chart.sh`.

#### configuration

(to edit it on your system run `/etc/netdata/edit-config charts.d.conf`). This file is also a BASH script.

In this file, you can place statements like this:

```
enable_all_charts="yes"
X="yes"
Y="no"
```

where `X` and `Y` are the names of individual charts.d collector scripts.

